{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "\n",
    "results_regression = pd.DataFrame(columns = ['model', 'task', 'R2'])\n",
    "results_classification = pd.DataFrame(columns = ['model', 'task', 'f1', 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('E:/git_exercise/Machine learning/boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%, предварительно выделив целевую переменную (колонка 'MEDV')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(         CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       " 477  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
       " 15    0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
       " 332   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
       " 423   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
       " 19    0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
       " ..        ...   ...    ...   ...     ...    ...   ...     ...   ...    ...   \n",
       " 106   0.17120   0.0   8.56   0.0  0.5200  5.836  91.9  2.2110   5.0  384.0   \n",
       " 270   0.29916  20.0   6.96   0.0  0.4640  5.856  42.1  4.4290   3.0  223.0   \n",
       " 348   0.01501  80.0   2.01   0.0  0.4350  6.635  29.7  8.3440   4.0  280.0   \n",
       " 435  11.16040   0.0  18.10   0.0  0.7400  6.629  94.6  2.1247  24.0  666.0   \n",
       " 102   0.22876   0.0   8.56   0.0  0.5200  6.405  85.4  2.7147   5.0  384.0   \n",
       " \n",
       "      PTRATIO       B  LSTAT  \n",
       " 477     20.2  349.48  24.91  \n",
       " 15      21.0  395.62   8.47  \n",
       " 332     16.9  362.25   7.83  \n",
       " 423     20.2    2.52  23.29  \n",
       " 19      21.0  390.95  11.28  \n",
       " ..       ...     ...    ...  \n",
       " 106     20.9  395.67  18.66  \n",
       " 270     18.6  388.65  13.00  \n",
       " 348     17.0  390.94   5.99  \n",
       " 435     20.2  109.85  23.27  \n",
       " 102     20.9   70.80  10.63  \n",
       " \n",
       " [404 rows x 13 columns],\n",
       "          CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       " 173   0.09178   0.0   4.05   0.0  0.510  6.416   84.1  2.6463   5.0  296.0   \n",
       " 274   0.05644  40.0   6.41   1.0  0.447  6.758   32.9  4.0776   4.0  254.0   \n",
       " 491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       " 72    0.09164   0.0  10.81   0.0  0.413  6.065    7.8  5.2873   4.0  305.0   \n",
       " 452   5.09017   0.0  18.10   0.0  0.713  6.297   91.8  2.3682  24.0  666.0   \n",
       " ..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       " 412  18.81100   0.0  18.10   0.0  0.597  4.628  100.0  1.5539  24.0  666.0   \n",
       " 436  14.42080   0.0  18.10   0.0  0.740  6.461   93.3  2.0026  24.0  666.0   \n",
       " 411  14.05070   0.0  18.10   0.0  0.597  6.657  100.0  1.5275  24.0  666.0   \n",
       " 86    0.05188   0.0   4.49   0.0  0.449  6.015   45.1  4.4272   3.0  247.0   \n",
       " 75    0.09512   0.0  12.83   0.0  0.437  6.286   45.0  4.5026   5.0  398.0   \n",
       " \n",
       "      PTRATIO       B  LSTAT  \n",
       " 173     16.6  395.50   9.04  \n",
       " 274     17.6  396.90   3.53  \n",
       " 491     20.1  390.11  18.07  \n",
       " 72      19.2  390.91   5.52  \n",
       " 452     20.2  385.09  17.27  \n",
       " ..       ...     ...    ...  \n",
       " 412     20.2   28.79  34.37  \n",
       " 436     20.2   27.49  18.05  \n",
       " 411     20.2   35.05  21.22  \n",
       " 86      18.5  395.99  12.86  \n",
       " 75      18.7  383.23   8.94  \n",
       " \n",
       " [102 rows x 13 columns],\n",
       " 477    12.0\n",
       " 15     19.9\n",
       " 332    19.4\n",
       " 423    13.4\n",
       " 19     18.2\n",
       "        ... \n",
       " 106    19.5\n",
       " 270    21.1\n",
       " 348    24.5\n",
       " 435    13.4\n",
       " 102    18.6\n",
       " Name: MEDV, Length: 404, dtype: float64,\n",
       " 173    23.6\n",
       " 274    32.4\n",
       " 491    13.6\n",
       " 72     22.8\n",
       " 452    16.1\n",
       "        ... \n",
       " 412    17.9\n",
       " 436     9.6\n",
       " 411    17.2\n",
       " 86     22.5\n",
       " 75     21.4\n",
       " Name: MEDV, Length: 102, dtype: float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame 'data'\n",
    "# целевая переменная'MEDV'\n",
    "\n",
    "# Разделение выборки на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('MEDV', axis=1), data['MEDV'], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso с параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 для стандартной регрессии: 0.6684825753971619\n",
      "R2 для Ridge: 0.6659608075261688\n",
      "R2 для Lasso: 0.6668687223368214\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lr_r2 = r2_score(y_test, lr.predict(X_test))\n",
    "ridge_r2 = r2_score(y_test, ridge.predict(X_test))\n",
    "lasso_r2 = r2_score(y_test, lasso.predict(X_test))\n",
    "\n",
    "print(\"R2 для стандартной регрессии:\", lr_r2)\n",
    "print(\"R2 для Ridge:\", ridge_r2)\n",
    "print(\"R2 для Lasso:\", lasso_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации двумя способами 1) GridSearchCV, 2) RidgeCV и LassoCV, в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по всем моделям и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший параметр для Ridge:  0.0001\n",
      "Лучший параметр для Lasso:  0.0001\n",
      "Лучший параметр для RidgeCV:  0.01\n",
      "Лучший параметр для LassoCV:  0.0001\n"
     ]
    }
   ],
   "source": [
    "# Создаем модель Ridge\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Создаем модель Lasso\n",
    "lasso_model = Lasso()\n",
    "\n",
    "\n",
    "border_values=[0.0001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000]\n",
    "# Создаем словарь параметров для поиска\n",
    "params = {'alpha': border_values}\n",
    "\n",
    "# Создаем экземпляр GridSearchCV для модели Ridge\n",
    "ridge_grid_search = GridSearchCV(ridge_model, param_grid=params)\n",
    "\n",
    "# Создаем экземпляр GridSearchCV для модели Lasso\n",
    "lasso_grid_search = GridSearchCV(lasso_model, param_grid=params)\n",
    "\n",
    "# Создаем модель RidgeCV\n",
    "ridge_cv = RidgeCV(alphas=border_values)\n",
    "\n",
    "# Создаем модель LassoCV\n",
    "lasso_cv = LassoCV(alphas=border_values)\n",
    "\n",
    "# Запускаем поиск\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "# Выводим результаты\n",
    "print(\"Лучший параметр для Ridge: \", ridge_grid_search.best_params_['alpha'])\n",
    "print(\"Лучший параметр для Lasso: \", lasso_grid_search.best_params_['alpha'])\n",
    "print(\"Лучший параметр для RidgeCV: \", ridge_cv.alpha_)\n",
    "print(\"Лучший параметр для LassoCV: \", lasso_cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведите масштабирование выборки (используйте Pipeline, StandardScaler, MinMaxScaler), посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний R2 для Ridge:  0.7245783031128651\n",
      "Средний R2 для Lasso:  0.2458342814681857\n"
     ]
    }
   ],
   "source": [
    "# Создаем модель Ridge\n",
    "#ridge_model = Ridge()\n",
    "\n",
    "# Создаем модель Lasso\n",
    "#lasso_model = Lasso()\n",
    "\n",
    "# Создаем Pipeline с StandardScaler\n",
    "scaler = StandardScaler()\n",
    "pipeline_ridge = Pipeline([('scaler', scaler), ('ridge', ridge_model)])\n",
    "\n",
    "# Создаем Pipeline с MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "pipeline_lasso = Pipeline([('scaler', scaler), ('lasso', lasso_model)])\n",
    "\n",
    "# Кросс-валидация\n",
    "ridge_scores = cross_val_score(pipeline_ridge, X_train, y_train, scoring='r2')\n",
    "lasso_scores = cross_val_score(pipeline_lasso, X_train, y_train, scoring='r2')\n",
    "\n",
    "\n",
    "print(\"Средний R2 для Ridge: \", ridge_scores.mean())\n",
    "print(\"Средний R2 для Lasso: \", lasso_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6636035715018218, 0.6685249100083176)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "ridge_cv = RidgeCV()\n",
    "lasso_cv = LassoCV()\n",
    "\n",
    "pipeline_ridge = Pipeline([('scaler', scaler), ('ridge_cv', ridge_cv)])\n",
    "pipeline_lasso = Pipeline([('scaler', minmax_scaler), ('lasso_cv', lasso_cv)])\n",
    "\n",
    "pipeline_ridge.fit(X_train, y_train)\n",
    "pipeline_lasso.fit(X_train, y_train)\n",
    "\n",
    "best_alpha_ridge = pipeline_ridge.named_steps['ridge_cv'].alpha_\n",
    "best_alpha_lasso = pipeline_lasso.named_steps['lasso_cv'].alpha_\n",
    "\n",
    "ridge_model = Ridge(alpha=best_alpha_ridge)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "lasso_model = Lasso(alpha=best_alpha_lasso)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "r2_ridge = r2_score(y_test, ridge_model.predict(X_test))\n",
    "r2_lasso = r2_score(y_test, lasso_model.predict(X_test))\n",
    "\n",
    "r2_ridge, r2_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 для Ridge и Lasso с параметрами по умолчанию и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha for standard scaling: 1\n",
      "0.8358387061836421\n",
      "score: 0.8473703650202432\n",
      "best alpha for minmax scaling: 0.1\n",
      "0.8458593856595996\n",
      "score: 0.8518360877299457\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge()\n",
    "lasso_model = Lasso()\n",
    "\n",
    "stand_scaler = StandardScaler()\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "border_values=[0.0001,0.0001,0.001,0.01,0.1,1,10,100,1000,10000,100000]\n",
    "\n",
    "params = {'ridge__alpha': [10 ** x for x in range(-5, 5)]}\n",
    "\n",
    "\n",
    "poly_features = PolynomialFeatures(2)\n",
    "\n",
    "\n",
    "\n",
    "stand_ridge = Pipeline([('poly_features', poly_features),('stand', stand_scaler), ('ridge', ridge_model)])\n",
    "grid_search = GridSearchCV(stand_ridge, param_grid=params, cv=3).fit(X_train, y_train)\n",
    "print('best alpha for standard scaling:', \n",
    "      grid_search.best_estimator_.get_params()['ridge__alpha'])\n",
    "print(grid_search.best_score_)\n",
    "print('score:', grid_search.score(X_test, y_test))\n",
    "\n",
    "minmax_ridge = Pipeline([('poly_features', poly_features),('minmax', minmax_scaler), ('ridge', ridge_model)])\n",
    "grid_search = GridSearchCV(minmax_ridge, param_grid=params, cv=3).fit(X_train, y_train)\n",
    "print('best alpha for minmax scaling:', \n",
    "      grid_search.best_estimator_.get_params()['ridge__alpha'])\n",
    "print(grid_search.best_score_)\n",
    "print('score:', grid_search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, добавив PolynomialFeatures, посчитайте R2 и сравните с предыдущими результатами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.859e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (alpha=0.001): R2 = -2.4244\n",
      "Lasso (alpha=0.001): R2 = 0.4792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.689e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (alpha=0.01): R2 = -1.9826\n",
      "Lasso (alpha=0.01): R2 = 0.7352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.657e+02, tolerance: 3.510e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge (alpha=0.1): R2 = -0.3707\n",
      "Lasso (alpha=0.1): R2 = 0.6383\n",
      "Ridge (alpha=1): R2 = -0.7205\n",
      "Lasso (alpha=1): R2 = 0.6621\n",
      "Ridge (alpha=10): R2 = 0.6019\n",
      "Lasso (alpha=10): R2 = 0.3878\n",
      "Ridge (alpha=100): R2 = 0.7878\n",
      "Lasso (alpha=100): R2 = -0.0159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "# Нормализуем данные\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Создаем полиномиальные признаки\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Создаем модели Ridge и Lasso с различными значениями альфа\n",
    "ridge_models = [Ridge(alpha=a) for a in [0.001, 0.01, 0.1, 1, 10, 100]]\n",
    "lasso_models = [Lasso(alpha=a) for a in [0.001, 0.01, 0.1, 1, 10, 100]]\n",
    "\n",
    "# Обучаем модели\n",
    "ridge_models_poly = [make_pipeline(poly, ridge_model) for ridge_model in ridge_models]\n",
    "lasso_models_poly = [make_pipeline(poly, lasso_model) for lasso_model in lasso_models]\n",
    "\n",
    "for ridge_model_poly, lasso_model_poly in zip(ridge_models_poly, lasso_models_poly):\n",
    "    ridge_model_poly.fit(X_train_poly, y_train)\n",
    "    lasso_model_poly.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Вычисляем R2 для каждой модели\n",
    "    ridge_r2 = r2_score(y_test, ridge_model_poly.predict(X_test_poly))\n",
    "    lasso_r2 = r2_score(y_test, lasso_model_poly.predict(X_test_poly))\n",
    "\n",
    "    print(f\"Ridge (alpha={ridge_model_poly.get_params()['ridge__alpha']}): R2 = {ridge_r2:.4f}\")\n",
    "    print(f\"Lasso (alpha={lasso_model_poly.get_params()['lasso__alpha']}): R2 = {lasso_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Подберите наилучшую модель (используйте Pipeline, GridSearchSCV) подбирая тип регуляризации (L1,L2), коэффициент регуляризации, метод масштабирования и степень полинома в PolynomialFeatures. Выведите итоговые параметры и результат R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.090e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.725e+01, tolerance: 2.764e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.995e+02, tolerance: 2.710e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.511e+02, tolerance: 2.730e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.104e+02, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.882e+02, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.944e+00, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.765e+01, tolerance: 2.882e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Параметры лучшей модели:\n",
      " {'poly__degree': 2, 'reg__alpha': 0.1}\n",
      "model    Best_Model\n",
      "task          task8\n",
      "R2         0.812814\n",
      "Name: 23, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.986e+01, tolerance: 2.948e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Создаем функцию, которая возвращает Pipeline с различными параметрами\n",
    "def create_pipeline(reg_type, reg_coef, poly_degree):\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=poly_degree)),\n",
    "        ('reg', reg_type(alpha=reg_coef))\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "# Создаем список параметров для GridSearchCV\n",
    "param_grid = {\n",
    "    'reg__alpha': [0.1, 0.5, 1.0],\n",
    "    'poly__degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Создаем модель и запускаем GridSearchCV\n",
    "model = GridSearchCV(create_pipeline(Lasso, 1.0, 2), param_grid)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Выводим параметры лучшей модели\n",
    "best_params = model.best_params_\n",
    "print('Параметры лучшей модели:\\n', best_params)\n",
    "\n",
    "# Вычисляем R2 для лучшей модели\n",
    "y_pred = model.predict(X_test)\n",
    "r2_best_model = r2_score(y_test, y_pred)\n",
    "\n",
    "# Записываем результаты в DataFrame\n",
    "results_regression.loc[23] = ['Best_Model', 'task8', r2_best_model]\n",
    "print(results_regression.loc[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Разделите выборку на признаки и целевую переменную(колонка class). Замените целевую переменную на числовые значения ('<=50K' - 1, '>50K' - 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ваш код ###\n",
    "\n",
    "data2['class'] = data2['class'].replace(['<=50K', '>50K'], [1, 0])\n",
    "\n",
    "# разделить DataFrame на признаки и целевую переменную\n",
    "X = data2.drop('class', axis=1)\n",
    "y = data2['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "### Ваш код ###\n",
    "'''\n",
    "f1_most_frequent = 0\n",
    "acc_most_frequent = 0\n",
    "results_classification.loc[0] = ['Most Frequent class', 'task10', f1_most_frequent, acc_most_frequent]\n",
    "'''\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Столбец, который содержит целевую переменную\n",
    "y_true = data2['class']\n",
    "\n",
    "# Самый часто встречающийся класс\n",
    "most_common_class = y_true.value_counts().index[0]\n",
    "\n",
    "# Создание предсказаний, присвоив всем значениям 'most_common_class'\n",
    "y_pred = y_true.apply(lambda x: most_common_class if x == most_common_class else x)\n",
    "\n",
    "# Вычисление метрик\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1_score = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'F1 score: {f1_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Выясните, присутствуют ли в данных пропуски. Если присутствуют, заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age         workclass  fnlwgt  education education-num  \\\n",
       "0      39         State-gov   77516  Bachelors            13   \n",
       "1      50  Self-emp-not-inc   83311  Bachelors            13   \n",
       "2      38           Private  215646    HS-grad             9   \n",
       "3      53           Private  234721       11th             7   \n",
       "4      28           Private  338409  Bachelors            13   \n",
       "...    ..               ...     ...        ...           ...   \n",
       "48837  39           Private  215419  Bachelors            13   \n",
       "48838  64                 ?  321403    HS-grad             9   \n",
       "48839  38           Private  374983  Bachelors            13   \n",
       "48840  44           Private   83891  Bachelors            13   \n",
       "48841  35      Self-emp-inc  182148  Bachelors            13   \n",
       "\n",
       "           marital-status         occupation    relationship  \\\n",
       "0           Never-married       Adm-clerical   Not-in-family   \n",
       "1      Married-civ-spouse    Exec-managerial         Husband   \n",
       "2                Divorced  Handlers-cleaners   Not-in-family   \n",
       "3      Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "4      Married-civ-spouse     Prof-specialty            Wife   \n",
       "...                   ...                ...             ...   \n",
       "48837            Divorced     Prof-specialty   Not-in-family   \n",
       "48838             Widowed                  ?  Other-relative   \n",
       "48839  Married-civ-spouse     Prof-specialty         Husband   \n",
       "48840            Divorced       Adm-clerical       Own-child   \n",
       "48841  Married-civ-spouse    Exec-managerial         Husband   \n",
       "\n",
       "                     race     sex capital-gain capital-loss hours-per-week  \\\n",
       "0                   White    Male         2174            0             40   \n",
       "1                   White    Male            0            0             13   \n",
       "2                   White    Male            0            0             40   \n",
       "3                   Black    Male            0            0             40   \n",
       "4                   Black  Female            0            0             40   \n",
       "...                   ...     ...          ...          ...            ...   \n",
       "48837               White  Female            0            0             36   \n",
       "48838               Black    Male            0            0             40   \n",
       "48839               White    Male            0            0             50   \n",
       "48840  Asian-Pac-Islander    Male         5455            0             40   \n",
       "48841               White    Male            0            0             60   \n",
       "\n",
       "      native-country class  \n",
       "0      United-States     1  \n",
       "1      United-States     1  \n",
       "2      United-States     1  \n",
       "3      United-States     1  \n",
       "4               Cuba     1  \n",
       "...              ...   ...  \n",
       "48837  United-States     1  \n",
       "48838  United-States     1  \n",
       "48839  United-States     1  \n",
       "48840  United-States     1  \n",
       "48841  United-States     0  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Ваш код ###\n",
    "from sklearn.impute import SimpleImputer\n",
    "missing_values = data2.isnull().sum()\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "data2 = pd.DataFrame(imputer.fit_transform(data2), columns=data2.columns)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Выберите колонки с числовыми и категориальными переменными (используя возможности pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Числовые:  Index(['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss',\n",
      "       'hours-per-week'],\n",
      "      dtype='object')\n",
      "Категориальные:  Index(['workclass', 'education', 'marital-status', 'occupation',\n",
      "       'relationship', 'race', 'sex', 'native-country', 'class'],\n",
      "      dtype='object')\n",
      "Все колонки:  Index(['age', 'capital-gain', 'capital-loss', 'class', 'education',\n",
      "       'education-num', 'fnlwgt', 'hours-per-week', 'marital-status',\n",
      "       'native-country', 'occupation', 'race', 'relationship', 'sex',\n",
      "       'workclass'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "# колонки с числовыми переменными\n",
    "numeric_columns = data.select_dtypes(include=['number']).columns\n",
    "\n",
    "# колонки с категориальными переменными\n",
    "categorical_columns = data.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "# оба списка в один\n",
    "all_columns = numeric_columns.union(categorical_columns)\n",
    "\n",
    "print('Числовые: ', numeric_columns)\n",
    "print('Категориальные: ', categorical_columns)\n",
    "print('Все колонки: ', all_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Создайте пайплайн по обработке числовых и категориальных значений колонок (используйте OneHotEncoder,MinMaxScaler) и посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression: accuracy=1.0000, f1=1.0000\n",
      "KNeighborsClassifier: accuracy=0.9724, f1=0.9822\n",
      "LinearSVC: accuracy=1.0000, f1=1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Загрузка данных\n",
    "\n",
    "df = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "df['class'] = df['class'].replace(['<=50K', '>50K'], [1, 0])\n",
    "categorical_columns = df.select_dtypes(include=['category', 'object']).columns\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "\n",
    "\n",
    "# Создание препроцессора для числовых колонок\n",
    "numeric_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "\n",
    "# Создание препроцессора для категориальных колонок\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
    "\n",
    "# Создание ColumnTransformer для объединения препроцессоров\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_columns),\n",
    "    ('cat', categorical_transformer, categorical_columns)\n",
    "])\n",
    "\n",
    "# Создание списка моделей\n",
    "models = [\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier()),\n",
    "    ('LinearSVC', LinearSVC())\n",
    "]\n",
    "# Перебор моделей и расчет cross_val_score\n",
    "scores = list()\n",
    "for name, model in models:\n",
    "    # Применение препроцессора к данным\n",
    "    X_prep = preprocessor.fit_transform(df)\n",
    "    \n",
    "    # Разделение данных на обучающую и тестовую выборки\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_prep, df['class'], random_state=0)\n",
    "    \n",
    "    # Обучение модели\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Прогнозирование на тестовой выборке\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Расчет метрик\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # Добавление результатов в список\n",
    "    scores.append((name, accuracy, f1))\n",
    "# Вывод результатов\n",
    "for name, accuracy, f1 in scores:\n",
    "    print(f'{name}: accuracy={accuracy:.4f}, f1={f1:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Можно заметить что в данных присутствуют значения '?', замените их самыми частыми значениями, (испольуйте SimpleImputer). Посчитайте cross_val_score по алгоритмам LogisticRegression, KNeighborsClassifier, LinearSVC по метрикам accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores:\n",
      "Logistic Regression: [0.99989764 0.99959054 0.99948812 0.99979525 0.99948812]\n",
      "K-Nearest Neighbors: [nan nan nan nan nan]\n",
      "Linear SVC: [1. 1. 1. 1. 1.]\n",
      "\n",
      "F1 scores:\n",
      "Logistic Regression: [0.99993189 0.99972763 0.99965956 0.9998638  0.99965956]\n",
      "K-Nearest Neighbors: [nan nan nan nan nan]\n",
      "Linear SVC: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Замена значений '?' на самые частые значения в каждом столбце\n",
    "imputer = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "df = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "\n",
    "categorical_columns = df.select_dtypes(['object']).columns\n",
    "df1=df[categorical_columns]\n",
    "df1 = pd.DataFrame(imputer.fit_transform(df1),columns=df1.columns)\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "ecc= pd.DataFrame(onehotencoder.fit_transform(df1))\n",
    "column_names = onehotencoder.get_feature_names_out()\n",
    "ecc.rename(columns=dict(zip(ecc.columns, column_names)), inplace=True)\n",
    "ecc.head()\n",
    "\n",
    "# Создаем матрицу признаков и целевой вектор\n",
    "X = ecc.drop('workclass_Private', axis=1)\n",
    "y = ecc['workclass_Private']\n",
    "\n",
    "# Создаем модели\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Вычисляем кросс-валидационные оценки для каждой модели\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "knn_scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
    "svc_scores = cross_val_score(svc, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Вычисляем кросс-валидационные оценки для каждой модели с использованием f1_score\n",
    "logreg_f1_scores = cross_val_score(logreg, X, y, cv=5, scoring='f1')\n",
    "knn_f1_scores = cross_val_score(knn, X, y, cv=5, scoring='f1')\n",
    "svc_f1_scores = cross_val_score(svc, X, y, cv=5, scoring='f1')\n",
    "\n",
    "# Выводим результаты\n",
    "print('Accuracy scores:')\n",
    "print('Logistic Regression:', logreg_scores)\n",
    "print('K-Nearest Neighbors:', knn_scores)\n",
    "print('Linear SVC:', svc_scores)\n",
    "\n",
    "print('\\nF1 scores:')\n",
    "print('Logistic Regression:', logreg_f1_scores)\n",
    "print('K-Nearest Neighbors:', knn_f1_scores)\n",
    "print('Linear SVC:', svc_f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Посчитайте cross_val_score по тем же алгоритмам и метрикам, если просто удалить значения '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:842: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 136, in __call__\n",
      "    score = scorer._score(\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 353, in _score\n",
      "    y_pred = method_caller(estimator, \"predict\", X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 85, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 246, in predict\n",
      "    if self._fit_method == \"brute\" and ArgKminClassMode.is_usable_for(\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 471, in is_usable_for\n",
      "    ArgKmin.is_usable_for(X, Y, metric)\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 115, in is_usable_for\n",
      "    and (is_numpy_c_ordered(X) or is_valid_sparse_matrix(X))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py\", line 99, in is_numpy_c_ordered\n",
      "    return hasattr(X, \"flags\") and X.flags.c_contiguous\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
      "\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores:\n",
      "Logistic Regression: [1.         0.99979527 0.99969287 1.         0.99979525]\n",
      "K-Nearest Neighbors: [nan nan nan nan nan]\n",
      "Linear SVC: [1. 1. 1. 1. 1.]\n",
      "\n",
      "F1 scores:\n",
      "Logistic Regression: [1.         0.99985257 0.99977884 1.         0.99985255]\n",
      "K-Nearest Neighbors: [nan nan nan nan nan]\n",
      "Linear SVC: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "### Ваш код ###\n",
    "'''\n",
    "f1_LR_del_missings = 0\n",
    "acc_LR_del_missings = 0\n",
    "f1_KNN_del_missings = 0\n",
    "acc_KNN_del_missings = 0\n",
    "f1_SVM_del_missings = 0\n",
    "acc_SVM_del_missings = 0\n",
    "results_classification.loc[7] = ['LogisticRegression_delete_missings', 'task15', f1_LR_del_missings, acc_LR_del_missings]\n",
    "results_classification.loc[8] = ['KNeighborsClassifier_delete_missings', 'task15', f1_KNN_del_missings, acc_KNN_del_missings]\n",
    "results_classification.loc[9] = ['LinearSVC_delete_missings', 'task15', f1_SVM_del_missings, acc_SVM_del_missings]\n",
    "'''\n",
    "df = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "\n",
    "imputer = SimpleImputer(missing_values='?', strategy='most_frequent')\n",
    "\n",
    "\n",
    "\n",
    "# Сохраните измененный DataFrame\n",
    "#df.to_csv('your_data_updated.csv', index=False)\n",
    "\n",
    "\n",
    "categorical_columns = df.select_dtypes(['object']).columns\n",
    "df1=df[categorical_columns]\n",
    "imputer.fit(df1.values)\n",
    "#df1 = pd.DataFrame(imputer.fit_transform(df1),columns=df1.columns)\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "ecc= pd.DataFrame(onehotencoder.fit_transform(df1))\n",
    "column_names = onehotencoder.get_feature_names_out()\n",
    "ecc.rename(columns=dict(zip(ecc.columns, column_names)), inplace=True)\n",
    "ecc.head()\n",
    "\n",
    "# Создаем матрицу признаков и целевой вектор\n",
    "X = ecc.drop('workclass_Private', axis=1)\n",
    "y = ecc['workclass_Private']\n",
    "\n",
    "# Создаем модели\n",
    "logreg = LogisticRegression()\n",
    "knn = KNeighborsClassifier()\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Вычисляем кросс-валидационные оценки для каждой модели\n",
    "logreg_scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "knn_scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
    "svc_scores = cross_val_score(svc, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Вычисляем кросс-валидационные оценки для каждой модели с использованием f1_score\n",
    "logreg_f1_scores = cross_val_score(logreg, X, y, cv=5, scoring='f1')\n",
    "knn_f1_scores = cross_val_score(knn, X, y, cv=5, scoring='f1')\n",
    "svc_f1_scores = cross_val_score(svc, X, y, cv=5, scoring='f1')\n",
    "\n",
    "# Выводим результаты\n",
    "print('Accuracy scores:')\n",
    "print('Logistic Regression:', logreg_scores)\n",
    "print('K-Nearest Neighbors:', knn_scores)\n",
    "print('Linear SVC:', svc_scores)\n",
    "\n",
    "print('\\nF1 scores:')\n",
    "print('Logistic Regression:', logreg_f1_scores)\n",
    "print('K-Nearest Neighbors:', knn_f1_scores)\n",
    "print('Linear SVC:', svc_f1_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 16. Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier на данных с замененными значениями '?' на самые частые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний результат для RandomForestClassifier: 1.0\n",
      "Средний результат для GradientBoostingClassifier: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "### Ваш код ###\n",
    "'''\n",
    "f1_RF = 0\n",
    "acc_RF = 0\n",
    "f1_GB = 0\n",
    "acc_GB = 0\n",
    "results_classification.loc[10] = ['RandomForestClassifier', 'task16', f1_RF, acc_RF]\n",
    "results_classification.loc[11] = ['GradientBoostingClassifier', 'task16', f1_GB, acc_GB]\n",
    "'''\n",
    "df = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].fillna(df[column].value_counts().index[0])\n",
    "categorical_columns = df.select_dtypes(['object']).columns\n",
    "df1=df[categorical_columns]\n",
    "#imputer.fit(df1.values)\n",
    "#df1 = pd.DataFrame(imputer.fit_transform(df1),columns=df1.columns)\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "ecc= pd.DataFrame(onehotencoder.fit_transform(df1))\n",
    "column_names = onehotencoder.get_feature_names_out()\n",
    "ecc.rename(columns=dict(zip(ecc.columns, column_names)), inplace=True)\n",
    "ecc.head()\n",
    "    \n",
    "    \n",
    "# Создаем модель RandomForestClassifier\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# Создаем модель GradientBoostingClassifier\n",
    "model_gb = GradientBoostingClassifier()\n",
    "\n",
    "# Оцениваем производительность модели RandomForestClassifier\n",
    "score_rf = cross_val_score(model_rf, ecc, ecc['workclass_Private'], cv=5, scoring='accuracy')\n",
    "\n",
    "# Оцениваем производительность модели GradientBoostingClassifier\n",
    "score_gb = cross_val_score(model_gb, ecc, ecc['workclass_Private'], cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Средний результат для RandomForestClassifier:\", score_rf.mean())\n",
    "print(\"Средний результат для GradientBoostingClassifier:\", score_gb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Подберите наилучшую модель, подбирая методы обработки колонок - масштабирование признаков, кодирование признаков и заполнение пропусков. Параметры алгоритмов оставьте по умолчанию. Выведите итоговые параметры и результат accuracy и f1_score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "E:\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier: accuracy=0.9997, f1_score=0.9998\n",
      "RandomForestClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "RandomForestClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "RandomForestClassifier: accuracy=0.9580, f1_score=0.9703\n",
      "RandomForestClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "GradientBoostingClassifier: accuracy=0.9997, f1_score=0.9998\n",
      "GradientBoostingClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "GradientBoostingClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "GradientBoostingClassifier: accuracy=0.9580, f1_score=0.9703\n",
      "GradientBoostingClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "LogisticRegression: accuracy=0.9997, f1_score=0.9998\n",
      "LogisticRegression: accuracy=1.0000, f1_score=1.0000\n",
      "LogisticRegression: accuracy=1.0000, f1_score=1.0000\n",
      "LogisticRegression: accuracy=0.9580, f1_score=0.9703\n",
      "LogisticRegression: accuracy=1.0000, f1_score=1.0000\n",
      "KNeighborsClassifier: accuracy=0.9997, f1_score=0.9998\n",
      "KNeighborsClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "KNeighborsClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "KNeighborsClassifier: accuracy=0.9580, f1_score=0.9703\n",
      "KNeighborsClassifier: accuracy=1.0000, f1_score=1.0000\n",
      "LinearSVC: accuracy=0.9997, f1_score=0.9998\n",
      "LinearSVC: accuracy=1.0000, f1_score=1.0000\n",
      "LinearSVC: accuracy=1.0000, f1_score=1.0000\n",
      "LinearSVC: accuracy=0.9580, f1_score=0.9703\n",
      "LinearSVC: accuracy=1.0000, f1_score=1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('E:/git_exercise/Machine learning/adult.csv')\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].fillna(df[column].value_counts().index[0])\n",
    "categorical_columns = df.select_dtypes(['object']).columns\n",
    "df1=df[categorical_columns]\n",
    "\n",
    "onehotencoder = OneHotEncoder(sparse_output=False)\n",
    "ecc= pd.DataFrame(onehotencoder.fit_transform(df1))\n",
    "column_names = onehotencoder.get_feature_names_out()\n",
    "ecc.rename(columns=dict(zip(ecc.columns, column_names)), inplace=True)\n",
    "ecc.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ecc.drop('workclass_Private', axis=1), ecc['workclass_Private'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Масштабирование признаков\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Кодирование признаков\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoder = OneHotEncoder()\n",
    "#X_train = encoder.fit_transform(X_train).toarray()\n",
    "#X_test = encoder.transform(X_test).toarray()\n",
    "\n",
    "# Заполнение пропусков\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer()\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Подбор наилучшей модели\n",
    "models = [\n",
    "    ('RandomForestClassifier', RandomForestClassifier()),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier()),\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier()),\n",
    "    ('LinearSVC', LinearSVC())\n",
    "]\n",
    "\n",
    "# Обучение моделей\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование на тестовой выборке\n",
    "predictions = [model.predict(X_test) for name, model in models]\n",
    "\n",
    "# Вычисление метрик\n",
    "scores = [\n",
    "    (name, accuracy_score(y_test, prediction), f1_score(y_test, prediction))\n",
    "    for name, model in models\n",
    "    for prediction in predictions\n",
    "]\n",
    "\n",
    "# Вывод результатов\n",
    "for name, accuracy, f1 in scores:\n",
    "    print(f'{name}: accuracy={accuracy:.4f}, f1_score={f1:.4f}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
